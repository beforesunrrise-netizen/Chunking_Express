import os
import pandas as pd
from datasets import load_dataset


class SquadDataProcessor:
    """
    SQuAD ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ê³  ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤.
    """

    def __init__(self, dataset_name: str = "squad", split: str = "train"):
        """
        ì´ˆê¸°í™” ì‹œ ë°ì´í„°ì…‹ ì´ë¦„ê³¼ ìŠ¤í”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        """
        self.dataset_name = dataset_name
        self.split = split
        self.ds = None

    def _load_data(self):
        """ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("ğŸ”„ Loading dataset...")
        if self.ds is None:
            self.ds = load_dataset(self.dataset_name, split=self.split)

    def _find_column(self, columns, keywords, fallback=None):
        """í‚¤ì›Œë“œì— ë§ëŠ” ì»¬ëŸ¼ ì´ë¦„ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        for key in keywords:
            matches = [col for col in columns if key in col.lower()]
            if matches:
                return matches[0]
        if fallback:
            return fallback
        raise ValueError(f"No column found matching keywords: {keywords}")

    def _extract_answer(self, ans):
        """ë‹µë³€ êµ¬ì¡°ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if isinstance(ans, dict) and "text" in ans:
            return ans["text"][0] if isinstance(ans["text"], list) and ans["text"] else ""
        return ""

    def process_and_save(self, n_samples: int, output_dir: str = "data", random_seed: int = 42):
        """
        ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³ , ëœë¤ ìƒ˜í”Œë§, ì „ì²˜ë¦¬ í›„ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

        Args:
            n_samples (int): ëœë¤ìœ¼ë¡œ ì¶”ì¶œí•  ìƒ˜í”Œì˜ ê°œìˆ˜.
            output_dir (str): ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬.
            random_seed (int): ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ.
        """
        # 1. ë°ì´í„° ë¡œë“œ
        self._load_data()

        # 2. ëœë¤ ìƒ˜í”Œë§
        print(f"ğŸ”€ Shuffling and selecting {n_samples} random samples...")
        if n_samples > len(self.ds):
            print(
                f"âš ï¸ Warning: n_samples ({n_samples}) is larger than the dataset size ({len(self.ds)}). Using all samples.")
            n_samples = len(self.ds)

        random_ds = self.ds.shuffle(seed=random_seed).select(range(n_samples))

        # 3. DataFrame ë³€í™˜ ë° ì „ì²˜ë¦¬
        print("ğŸ“„ Converting to DataFrame and processing...")
        df = random_ds.to_pandas()

        question_col = self._find_column(df.columns, ["question", "query"])
        context_col = self._find_column(df.columns, ["context", "paragraph"])
        answer_col = self._find_column(df.columns, ["answers", "answer"])

        df_filtered = df[[question_col, context_col, answer_col]].dropna()
        df_filtered.columns = ["question", "context", "answer"]
        df_filtered["answer"] = df_filtered["answer"].apply(self._extract_answer)

        # 4. íŒŒì¼ ì €ì¥
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"squad_{self.split}_{n_samples}_random.json")

        print(f"ğŸ’¾ Saving to '{output_path}'...")
        df_filtered.to_json(output_path, orient="records", force_ascii=False, indent=2)
        print(f"ğŸ‰ Successfully saved {len(df_filtered)} samples to '{output_path}'")
        return output_path


# --- í´ë˜ìŠ¤ ì‹¤í–‰ ì˜ˆì‹œ ---
if __name__ == "__main__":
    # í”„ë¡œì„¸ì„œ ê°ì²´ ìƒì„±
    processor = SquadDataProcessor()
    # 100ê°œ ìƒ˜í”Œì„ ì²˜ë¦¬í•˜ê³  ì €ì¥
    processor.process_and_save(n_samples=5)
    # 200ê°œ ìƒ˜í”Œì„ ë‹¤ë¥¸ ì‹œë“œë¡œ ì²˜ë¦¬í•˜ê³  ì €ì¥
    # processor.process_and_save(n_samples=200, random_seed=123)
import os
import pandas as pd
from datasets import load_dataset
from typing import Dict, Any


class SquadDataProcessor:
    """
    SQuAD í˜•ì‹ì˜ ë°ì´í„°ì…‹ì„ RAG ì‹¤í—˜ì„ ìœ„í•œ ìµœì¢… JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì¶œë ¥ í˜•ì‹: {"id":..., "title":..., "question":..., "context":..., "answer":...}
    """

    def __init__(self, dataset_name: str = "squad", split: str = "train"):
        self.dataset_name = dataset_name
        self.split = split
        self.ds = None

    def _load_data(self):
        if self.ds is None:
            print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘: {self.dataset_name}, ìŠ¤í”Œë¦¿: {self.split}")
            self.ds = load_dataset(self.dataset_name, split=self.split)
            print("ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ.")

    def process_and_save(self, num_samples: int, output_dir: str = "data", random_seed: int = 42):
        self._load_data()

        if num_samples > len(self.ds):
            print(f"ê²½ê³ : ìš”ì²­ëœ ìƒ˜í”Œ ìˆ˜({num_samples})ê°€ ë°ì´í„°ì…‹ í¬ê¸°({len(self.ds)})ë³´ë‹¤ í½ë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            num_samples = len(self.ds)

        print(f"{num_samples}ê°œì˜ ìƒ˜í”Œì„ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤...")
        sampled_dataset = self.ds.shuffle(seed=random_seed).select(range(num_samples))

        df = sampled_dataset.to_pandas()

        # 'answers' ë”•ì…”ë„ˆë¦¬ì—ì„œ 'text' ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶”ì¶œ
        df['answer'] = df['answers'].apply(
            lambda ans_dict: ans_dict['text'][0] if ans_dict['text'] else ""
        )

        # ë‹µë³€ì´ ì—†ëŠ” ìƒ˜í”Œì€ ì œì™¸
        df = df[df['answer'] != ''].copy()

        # --- â˜…â˜…â˜… ìµœì¢… ìˆ˜ì • ë¡œì§ â˜…â˜…â˜… ---
        # idì™€ titleì„ í¬í•¨í•œ ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ì„ ì„ íƒí•©ë‹ˆë‹¤.
        final_df = df[['id', 'title', 'question', 'context', 'answer']]
        # --- â˜…â˜…â˜… ìˆ˜ì • ì™„ë£Œ â˜…â˜…â˜… ---


        # ê²°ê³¼ ì €ì¥
        os.makedirs(output_dir, exist_ok=True)
        file_name = f"rag_squad_{self.split}_{len(final_df)}_samples.json"
        output_path = os.path.join(output_dir, file_name)

        print(f"ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ '{output_path}'ì— ì €ì¥í•©ë‹ˆë‹¤...")
        final_df.to_json(output_path, orient="records", force_ascii=False, indent=2)

        print("-" * 50)
        print("âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
        print(f"ìµœì¢… ìƒì„± íŒŒì¼: {output_path}")
        print(f"ì´ {len(final_df)}ê°œì˜ ìœ íš¨í•œ ìƒ˜í”Œì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\nğŸ“‹ ìµœì¢… ë°ì´í„° êµ¬ì¡°:")
        print("   - id: ê³ ìœ  ì‹ë³„ì")
        print("   - title: ë¬¸ì„œ ì œëª©")
        print("   - question: ì‚¬ìš©ì ì§ˆë¬¸")
        print("   - context: ì •ë‹µì„ í¬í•¨í•œ ì›ë³¸ ë¬¸ì„œ")
        print("   - answer: ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µ")
        print("\nì´ì œ ì´ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ RAG í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("-" * 50)

        return output_path


# --- ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ ---
if __name__ == "__main__":
    processor = SquadDataProcessor(dataset_name="squad", split="train")
    processor.process_and_save(num_samples=100)